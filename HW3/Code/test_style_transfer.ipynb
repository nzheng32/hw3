{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "signed-hormone",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import PIL\n",
    "\n",
    "from style_modules import ContentLoss, StyleLoss, TotalVariationLoss\n",
    "from style_utils import features_from_img, extract_features, rel_error, style_transfer\n",
    "from image_utils import preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "technological-catering",
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_loss_test(correct, content_loss):\n",
    "    content_image = 'styles_images/tubingen.jpg'\n",
    "    image_size = 192\n",
    "    content_layer = 3\n",
    "    content_weight = 6e-2\n",
    "\n",
    "    c_feats, content_img_var = features_from_img(content_image, image_size, cnn, dtype)\n",
    "\n",
    "    bad_img = Variable(torch.zeros(*content_img_var.data.size()))\n",
    "    feats = extract_features(bad_img, cnn)\n",
    "\n",
    "    student_output = content_loss(content_weight, c_feats[content_layer], feats[content_layer]).data.numpy()\n",
    "    error = rel_error(correct, student_output)\n",
    "    print('Content Loss Maximum error is {:.3f}'.format(error))\n",
    "\n",
    "def gram_matrix_test(correct, style_loss):\n",
    "    style_image = 'styles_images/starry_night.jpg'\n",
    "    style_size = 192\n",
    "    feats, _ = features_from_img(style_image, style_size, cnn, dtype)\n",
    "    student_output = style_loss.gram_matrix(feats[5].clone()).data.numpy()\n",
    "    error = rel_error(correct, student_output)\n",
    "    print('Gram Matrix Maximum error is {:.3f}'.format(error))\n",
    "\n",
    "\n",
    "def style_loss_test(correct, style_loss):\n",
    "    content_image = 'styles_images/tubingen.jpg'\n",
    "    style_image = 'styles_images/starry_night.jpg'\n",
    "    image_size = 192\n",
    "    style_size = 192\n",
    "    style_layers = [1, 4, 6, 7]\n",
    "    style_weights = [300000, 1000, 15, 3]\n",
    "\n",
    "    c_feats, _ = features_from_img(content_image, image_size, cnn, dtype)\n",
    "    feats, _ = features_from_img(style_image, style_size, cnn, dtype)\n",
    "    style_targets = []\n",
    "    for idx in style_layers:\n",
    "        style_targets.append(style_loss.gram_matrix(feats[idx].clone()))\n",
    "\n",
    "    student_output = style_loss(c_feats, style_layers, style_targets, style_weights).data.numpy()\n",
    "    error = rel_error(correct, student_output)\n",
    "    print('Style Loss Error is {:.3f}'.format(error))\n",
    "\n",
    "\n",
    "def tv_loss_test(correct, tv_loss):\n",
    "    content_image = 'styles_images/tubingen.jpg'\n",
    "    image_size = 192\n",
    "    tv_weight = 2e-2\n",
    "\n",
    "    content_img = preprocess(PIL.Image.open(content_image), size=image_size)\n",
    "    content_img_var = Variable(content_img.type(dtype))\n",
    "\n",
    "    student_output = tv_loss(content_img_var, tv_weight).data.numpy()\n",
    "    error = rel_error(correct, student_output)\n",
    "    print('TV Loss Error is {:.3f}'.format(error))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "stylish-infrastructure",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.FloatTensor\n",
    "# Uncomment out the following line if you're on a machine with a GPU set up for PyTorch!\n",
    "# dtype = torch.cuda.FloatTensor\n",
    "\n",
    "cnn = torchvision.models.squeezenet1_1(pretrained=True).features\n",
    "cnn.type(dtype)\n",
    "\n",
    "# Fix the weights of the pretrained network\n",
    "for param in cnn.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "answers = np.load('data/style-transfer-checks.npz') # for local test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "centered-banana",
   "metadata": {},
   "source": [
    "### Test content loss (1pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coral-monday",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_loss = ContentLoss()\n",
    "content_loss_test(answers['cl_out'], content_loss) # should print out 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colonial-bosnia",
   "metadata": {},
   "source": [
    "### Test style loss (2pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "damaged-union",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gram Matrix Maximum error is 0.000\n",
      "Style Loss Error is 0.000\n"
     ]
    }
   ],
   "source": [
    "style_loss = StyleLoss()\n",
    "gram_matrix_test(answers['gm_out'], style_loss) # should print out 0.0\n",
    "style_loss_test(answers['sl_out'], style_loss) # should print out 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immediate-broadcasting",
   "metadata": {},
   "source": [
    "### Test total variation loss (1pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "loving-accent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TV Loss Error is 0.000\n"
     ]
    }
   ],
   "source": [
    "tv_loss = TotalVariationLoss()\n",
    "tv_loss_test(answers['tv_out'], tv_loss) # should print out 0.0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
