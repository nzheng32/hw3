{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nzheng32/hw3/blob/main/CXproject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Y1RJQMdSOb6"
      },
      "source": [
        "# CX 4240 Project - University ranking\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUcaY1ZyaSmF"
      },
      "source": [
        "<img src=\"https://media.istockphoto.com/photos/law-quadrangle-university-of-michigan-ann-arbor-aerial-view-picture-id1319991057?b=1&k=20&m=1319991057&s=170667a&w=0&h=MXEuQhq56vOInXq7NqZcBynvLxynnBIN8bwgm4dWE-U=\" width=800 height=400 />"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oBJKSXmTXsiw"
      },
      "outputs": [],
      "source": [
        "# Code to read csv file into colaboratory:\n",
        "# add shortcut to google drive from the shared folder, then the following code will ask permission to access your google drive\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cto11Wkxb3g7"
      },
      "outputs": [],
      "source": [
        "cd gdrive/MyDrive//Final CX4240"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0karVMHpdfSV"
      },
      "source": [
        "## Imports\n",
        "\n",
        "We are only using numpy, pandas, and a few plotting functions here. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dlYh2uxmciiz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5k-5LlOFe1lw"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JSmN9XHOe6p1"
      },
      "outputs": [],
      "source": [
        "# Code for Pearson Correlation Matrix\n",
        "\n",
        "university = pd.read_csv(\"PCMRank.csv\")\n",
        "# print(university)\n",
        "corr_matrix = university.corr()\n",
        "fig, ax = plt.subplots(figsize=(15,15))\n",
        "sns.heatmap(corr_matrix, annot = True, linewidths = 0.001, ax = ax)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Candidate Model 1: Linear Regression"
      ],
      "metadata": {
        "id": "N3ZNJy0G374K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bVh8OIstw1DW"
      },
      "outputs": [],
      "source": [
        "# Code to run Linear Regression on all features in the Pearson Correlation Matrix\n",
        "\n",
        "\n",
        "x = university.drop('Rankings', axis = 1)\n",
        "y = university[\"Rankings\"]\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)\n",
        "\n",
        "x_train_new = x_train.drop('Name', axis = 1)\n",
        "x_test_new = x_test.drop('Name', axis = 1)\n",
        "\n",
        "\n",
        "LR = LinearRegression()\n",
        "\n",
        "LR.fit(x_train_new,y_train)\n",
        "\n",
        "y_prediction =  LR.predict(x_test_new)\n",
        "\n",
        "print(pd.concat([pd.Series(np.array(x_test[\"Name\"])), pd.Series(y_prediction)], axis = 1))\n",
        "# print(list(zip(list(x_test_new.columns), LR.coef_)))\n",
        "\n",
        "# Accuracy\n",
        "\n",
        "LR.fit(x_train_new,y_train)\n",
        "r2_score = LR.score(x_test_new,y_test)\n",
        "print(\"Accuracy:\", r2_score*100,'%')\n",
        "\n",
        "# Mean Squared Loss\n",
        "\n",
        "loss = mse = (np.square(y_prediction - y_test)).mean(axis=None)\n",
        "print(\"Loss:\", loss)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Code to run Linear Regression on only the most correlated features (above |0.6| in Pearson Correlation Matrix)\n",
        "\n",
        "x = university[['Name', 'SAT Critical Reading 25th percentile score', 'SAT Critical Reading 75th percentile score', 'SAT MATH 25 percentiles score', 'SAT Math 75th percentile score', 'Percent admitted - total', 'Graduation rate - Bachelor degree within 6 years, total']]\n",
        "y = university[\"Rankings\"]\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)\n",
        "\n",
        "x_train_new = x_train.drop('Name', axis = 1)\n",
        "x_test_new = x_test.drop('Name', axis = 1)\n",
        "\n",
        "\n",
        "LR = LinearRegression()\n",
        "\n",
        "LR.fit(x_train_new,y_train)\n",
        "\n",
        "y_prediction =  LR.predict(x_test_new)\n",
        "\n",
        "print(pd.concat([pd.Series(np.array(x_test[\"Name\"])), pd.Series(y_prediction)], axis = 1))\n",
        "# print(list(zip(list(x_test_new.columns), LR.coef_)))\n",
        "\n",
        "# Accuracy\n",
        "\n",
        "LR.fit(x_train_new,y_train)\n",
        "r2_score = LR.score(x_test_new,y_test)\n",
        "print(\"Accuracy:\", r2_score*100,'%')\n",
        "# Mean Squared Loss\n",
        "\n",
        "loss = mse = (np.square(y_prediction - y_test)).mean(axis=None)\n",
        "print(\"Loss:\", loss)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "id": "6M-eyHiUuWkY",
        "outputId": "11166ac7-2b72-4099-98b7-c303b6bcfa28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-cf664be58472>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Code to run Linear Regression on only the most correlated features (above |0.6| in Pearson Correlation Matrix)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muniversity\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'SAT Critical Reading 25th percentile score'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'SAT Critical Reading 75th percentile score'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'SAT MATH 25 percentiles score'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'SAT Math 75th percentile score'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Percent admitted - total'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Graduation rate - Bachelor degree within 6 years, total'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muniversity\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Rankings\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'university' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Candidate Model 2: Random Forest Regression"
      ],
      "metadata": {
        "id": "_-ecXJ8p4DU3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = university.drop('Rankings', axis = 1)\n",
        "y = university[\"Rankings\"]\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)\n",
        "\n",
        "x_train_new = x_train.drop('Name', axis = 1)\n",
        "x_test_new = x_test.drop('Name', axis = 1)\n",
        "accurracy_list = []\n",
        "mls_loss_list = []\n",
        "numberTree = []\n",
        "best_acc = 0\n",
        "best_loss = 10e3\n",
        "best_tree = 0\n",
        "\n",
        "for i in range(80, 200, 5):\n",
        "  regr = RandomForestRegressor(n_estimators = i, max_depth=16, random_state=3)\n",
        "  regr.fit(x_train_new, y_train)\n",
        "\n",
        "  y_prediction =  regr.predict(x_test_new)\n",
        "\n",
        "  # Accuracy \n",
        "  regr.fit(x_train_new,y_train)\n",
        "  r2_score = regr.score(x_test_new,y_test)\n",
        "\n",
        "\n",
        "  # Mean Squared Loss\n",
        "  loss = mse = (np.square(y_prediction - y_test)).mean(axis=None)\n",
        "  numberTree.append(i)\n",
        "  accurracy_list.append(r2_score*100)\n",
        "  mls_loss_list.append(loss)\n",
        "  if r2_score*100 > best_acc:\n",
        "    best_acc = r2_score*100\n",
        "    best_tree = i\n",
        "  if loss < best_loss:\n",
        "    best_loss = loss\n",
        "\n",
        "\n",
        "plt.plot(numberTree, accurracy_list, color='green')\n",
        "plt.title(\"Accuracy vs Number of trees used\")\n",
        "plt.xlabel('number of trees') \n",
        "plt.ylabel('accuracy') \n",
        "plt.show()\n",
        "\n",
        "plt.plot(numberTree, mls_loss_list, color='green')\n",
        "plt.title(\"MLS loss vs Number of trees used\")\n",
        "plt.xlabel('number of trees') \n",
        "plt.ylabel('loss') \n",
        "plt.show()\n",
        "\n",
        "print(\"The best accuracy achieved is \" + str(best_acc) + \" with number of trees equal to \" + str(best_tree))\n",
        "print(\"The best loss achieved is \" + str(best_loss))\n"
      ],
      "metadata": {
        "id": "XI-2YfGO4xcE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##K-Means Clustering"
      ],
      "metadata": {
        "id": "LRMaWgk8PnNW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn import metrics\n",
        "from scipy.spatial.distance import cdist\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data = pd.read_csv(\"College_Fit_Data.csv\")\n",
        "\n",
        "new_data = data.drop(['Name'], axis = 1)\n",
        "\n",
        "\n",
        "\n",
        "kmeans = KMeans(n_clusters = 44)\n",
        "\n",
        "y = kmeans.fit_predict(new_data)\n",
        "\n",
        "data['Cluster'] = y\n",
        "\n",
        "print(data[['Name', 'Cluster']])\n",
        "\n",
        "name_cluster = list(zip(data.Name, data.Cluster))\n",
        "\n",
        "name_cluster_dict = {}\n",
        "for i in name_cluster:\n",
        "  if i[1] not in name_cluster_dict:\n",
        "    a_list = []\n",
        "    a_list.append(i[0])\n",
        "    name_cluster_dict[i[1]] = a_list\n",
        "  else:\n",
        "    current = name_cluster_dict[i[1]]\n",
        "    current.append(i[0])\n",
        "    name_cluster_dict[i[1]] = current\n",
        "\n",
        "print(name_cluster_dict)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# sil = []\n",
        "# kmax = 100\n",
        "\n",
        "# for k in range(2, kmax+1):\n",
        "#   kmeans = KMeans(n_clusters = k).fit(new_data)\n",
        "#   labels = kmeans.labels_\n",
        "#   sil.append(silhouette_score(new_data, labels, metric = 'euclidean'))\n",
        "\n",
        "# range_of_values = np.array(list(range(1, 100)))\n",
        "# sil = np.array(sil)\n",
        "# plt.plot(range_of_values, sil)\n",
        "# plt.show()\n",
        "# print(np.amax(sil))\n",
        "\n",
        "# range_of_values = pd.Series(range_of_values)\n",
        "# sil = pd.Series(sil)\n",
        "\n",
        "# sil_values = pd.concat([range_of_values, sil], axis=1)\n",
        "# sil_values.columns = ['k', 's_coef']\n",
        "\n",
        "# print(sil_values[sil_values.s_coef == sil_values.s_coef.max()])\n"
      ],
      "metadata": {
        "id": "WcJnkk_yLATw"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "CXproject.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}